# üéØ Free-First Architecture - Semantic Search

**M·ª•c ti√™u:** H·ªá th·ªëng Semantic Search ho·∫°t ƒë·ªông ho√†n to√†n local, kh√¥ng ph·ª• thu·ªôc cloud API tr·∫£ ph√≠, nh∆∞ng c√≥ c·∫•u tr√∫c s·∫µn ƒë·ªÉ sau n√†y b·∫≠t OpenAI/Vertex AI ch·ªâ b·∫±ng 1 config.

**Fixed Architecture Pattern** - C√≥ th·ªÉ √°p d·ª•ng l·∫°i cho c√°c d·ª± √°n kh√°c.

---

## üß© Ki·∫øn Tr√∫c T·ªïng Quan

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     TypeScript Backend              ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ
‚îÇ  semanticSearchService.ts           ‚îÇ
‚îÇ  hybridSearchService.ts             ‚îÇ
‚îÇ  embeddingProvider.ts (pluggable)   ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ
‚îÇ  Embedding Provider Layer           ‚îÇ
‚îÇ  ‚îú‚îÄ Local (free, default)           ‚îÇ
‚îÇ  ‚îú‚îÄ OpenAI (paid, optional)         ‚îÇ
‚îÇ  ‚îî‚îÄ Vertex AI (paid, optional)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Local Embedding Server (Python)    ‚îÇ
‚îÇ  FastAPI + Sentence Transformers    ‚îÇ
‚îÇ  Port: 8000                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PostgreSQL + pgvector (Docker)     ‚îÇ
‚îÇ  Local database, vector index       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## ‚úÖ ∆Øu ƒêi·ªÉm Ki·∫øn Tr√∫c Free-First

| ∆Øu ƒëi·ªÉm | M√¥ t·∫£ |
|---------|-------|
| üí∏ **Kh√¥ng t·ªën chi ph√≠** | Kh√¥ng g·ªçi API tr·∫£ ph√≠ n√†o |
| üîí **B·∫£o m·∫≠t tuy·ªát ƒë·ªëi** | To√†n b·ªô d·ªØ li·ªáu ·ªü local |
| üß† **M√¥ h√¨nh embedding kh√° m·∫°nh** | MiniLM ƒë·∫°t ~85% hi·ªáu nƒÉng OpenAI |
| ‚öôÔ∏è **C·∫•u tr√∫c m·ªü r·ªông d·ªÖ** | S·∫µn s√†ng b·∫≠t Vertex/OpenAI khi c·∫ßn |
| üß© **Th·ª≠ nghi·ªám offline** | D·ªÖ debug, kh√¥ng ph·ª• thu·ªôc m·∫°ng |
| üîÑ **Fixed architecture** | Pattern c√≥ th·ªÉ t√°i s·ª≠ d·ª•ng |

---

## üöÄ Setup Local-First (Free)

### B∆∞·ªõc 1: Setup PostgreSQL + pgvector (Docker)

```bash
# Ch·∫°y PostgreSQL v·ªõi pgvector
docker run -d \
  --name pgvector-local \
  -e POSTGRES_PASSWORD=postgres \
  -e POSTGRES_DB=bot_writing_advanced \
  -p 5432:5432 \
  ankane/pgvector

# Verify
docker ps | grep pgvector-local
```

**L∆∞u √Ω:** N·∫øu ƒë√£ c√≥ PostgreSQL local, ch·ªâ c·∫ßn enable extension:
```sql
CREATE EXTENSION IF NOT EXISTS vector;
```

### B∆∞·ªõc 2: Setup Local Embedding Server (Python)

**C√†i ƒë·∫∑t dependencies:**
```bash
# Python 3.8+ required
pip install sentence-transformers fastapi uvicorn
```

**Ch·∫°y embedding server:**
```bash
# T·ª´ th∆∞ m·ª•c project root
python local_embedding_server.py

# Ho·∫∑c v·ªõi uvicorn
uvicorn local_embedding_server:app --host 0.0.0.0 --port 8000
```

**Verify server:**
```bash
curl http://localhost:8000/health
# Expected: {"status":"healthy","model":"all-MiniLM-L6-v2"}
```

### B∆∞·ªõc 3: Update Database Schema (n·∫øu c·∫ßn)

**Local model d√πng 384 dimensions:**
```sql
-- Update schema n·∫øu ƒëang d√πng 768 dims
ALTER TABLE recent_chapters 
  ALTER COLUMN embedding_vector TYPE vector(384);

ALTER TABLE chapter_chunks 
  ALTER COLUMN chunk_embedding TYPE vector(384);

ALTER TABLE embedding_cache 
  ALTER COLUMN embedding_vector TYPE vector(384);
```

**Ho·∫∑c gi·ªØ 768 v√† d√πng model l·ªõn h∆°n:**
```bash
# Set environment variable
export EMBEDDING_MODEL=all-mpnet-base-v2  # 768 dims
python local_embedding_server.py
```

### B∆∞·ªõc 4: Configure Backend

**File:** `.env`

```env
# Embedding Provider (free-first)
EMBEDDING_PROVIDER=local

# Local Embedding Server URL
LOCAL_EMBEDDING_API_URL=http://localhost:8000

# Database (local)
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/bot_writing_advanced
```

### B∆∞·ªõc 5: Test

```bash
# Start backend
npm run server

# Test embedding generation
# (s·∫Ω t·ª± ƒë·ªông d√πng local provider)
```

---

## üîÑ Switch Provider (Sau N√†y)

### Option 1: Switch to OpenAI

**File:** `.env`
```env
EMBEDDING_PROVIDER=openai
OPENAI_API_KEY=sk-...

# Update schema to 1536 dims
# ALTER TABLE ... ALTER COLUMN embedding_vector TYPE vector(1536);
```

**Code t·ª± ƒë·ªông switch** - kh√¥ng c·∫ßn thay ƒë·ªïi code!

### Option 2: Switch to Vertex AI

**File:** `.env`
```env
EMBEDDING_PROVIDER=vertex-ai
GOOGLE_CLOUD_PROJECT_ID=your-project-id
GOOGLE_APPLICATION_CREDENTIALS=path/to/service-account.json

# Schema: 768 dims (default)
```

**Code t·ª± ƒë·ªông switch** - kh√¥ng c·∫ßn thay ƒë·ªïi code!

---

## üìä So S√°nh Providers

| Provider | Dimensions | Cost | Setup | Performance | Data Privacy |
|----------|-----------|------|-------|-------------|--------------|
| **Local** | 384/768 | üí∞ Free | Medium | ~85% OpenAI | üîí 100% Local |
| **OpenAI** | 1536 | üí∞üí∞ Paid | Easy | 100% | ‚ö†Ô∏è Cloud |
| **Vertex AI** | 768 | üí∞üí∞ Paid | Medium | ~95% OpenAI | ‚ö†Ô∏è Cloud |

---

## üß™ Testing

### Test 1: Local Embedding Server

```bash
# Health check
curl http://localhost:8000/health

# Single embedding
curl -X POST http://localhost:8000/embed \
  -H "Content-Type: application/json" \
  -d '{"text": "test embedding"}'

# Batch embeddings
curl -X POST http://localhost:8000/embed/batch \
  -H "Content-Type: application/json" \
  -d '{"texts": ["text 1", "text 2"]}'
```

### Test 2: Backend Integration

```typescript
// Test script
import { generateEmbedding, getEmbeddingModelInfo } from './server/services/vertexEmbeddingService';

(async () => {
  const info = getEmbeddingModelInfo();
  console.log('Provider:', info.provider);
  console.log('Model:', info.model);
  console.log('Dimensions:', info.dimensions);
  
  const embedding = await generateEmbedding("Test semantic search");
  console.log('Embedding length:', embedding.length);
  console.log('First 5 values:', embedding.slice(0, 5));
})();
```

### Test 3: Semantic Search

```typescript
import { semanticSearch } from './server/services/semanticSearchService';

(async () => {
  const results = await semanticSearch(
    "t√¨m ki·∫øm ng·ªØ nghƒ©a v·ªõi c∆° s·ªü d·ªØ li·ªáu",
    "book-id-here",
    5
  );
  console.log('Search results:', results);
})();
```

---

## üìù Environment Variables

### Local Provider (Default)
```env
EMBEDDING_PROVIDER=local
LOCAL_EMBEDDING_API_URL=http://localhost:8000
EMBEDDING_MODEL=all-MiniLM-L6-v2  # Optional, for Python server
```

### OpenAI Provider
```env
EMBEDDING_PROVIDER=openai
OPENAI_API_KEY=sk-...
```

### Vertex AI Provider
```env
EMBEDDING_PROVIDER=vertex-ai
GOOGLE_CLOUD_PROJECT_ID=your-project-id
GOOGLE_APPLICATION_CREDENTIALS=path/to/service-account.json
```

---

## üîß Architecture Pattern (Fixed & Reusable)

### Provider Interface

```typescript
interface IEmbeddingProvider {
  generateEmbedding(text: string): Promise<number[]>;
  generateEmbeddingsBatch(texts: string[]): Promise<number[][]>;
  getDimensions(): number;
  getModelName(): string;
  getProvider(): EmbeddingProvider;
}
```

### Factory Pattern

```typescript
function createEmbeddingProvider(): IEmbeddingProvider {
  const provider = process.env.EMBEDDING_PROVIDER || 'local';
  
  switch (provider) {
    case 'local': return new LocalEmbeddingProvider();
    case 'openai': return new OpenAIEmbeddingProvider();
    case 'vertex-ai': return new VertexAIEmbeddingProvider();
    default: return new LocalEmbeddingProvider();
  }
}
```

**Pattern n√†y c√≥ th·ªÉ t√°i s·ª≠ d·ª•ng cho b·∫•t k·ª≥ d·ª± √°n n√†o!**

---

## üì¶ Dependencies

### Backend (TypeScript)
```json
{
  "dependencies": {
    "pg": "^8.16.3",
    "@types/pg": "^8.15.6"
  },
  "optionalDependencies": {
    "openai": "^4.0.0",  // Only if using OpenAI
    "google-auth-library": "^9.0.0"  // Only if using Vertex AI
  }
}
```

### Local Embedding Server (Python)
```txt
sentence-transformers>=2.2.0
fastapi>=0.100.0
uvicorn>=0.23.0
```

---

## üéØ Checklist Implementation

- [ ] Setup PostgreSQL + pgvector (Docker ho·∫∑c local)
- [ ] Install Python dependencies
- [ ] Start local embedding server
- [ ] Update `.env` v·ªõi `EMBEDDING_PROVIDER=local`
- [ ] Update database schema (384 dims n·∫øu c·∫ßn)
- [ ] Test embedding generation
- [ ] Test semantic search
- [ ] Verify kh√¥ng c√≥ API calls ra ngo√†i
- [ ] Document cho team

---

## üîó T√†i Li·ªáu Li√™n Quan

- [SEMANTIC_SEARCH_IMPLEMENTATION.md](./SEMANTIC_SEARCH_IMPLEMENTATION.md) - Implementation details
- [QUICK_START.md](./QUICK_START.md) - Quick start guide
- [PROJECT_STATUS.md](./PROJECT_STATUS.md) - Project status

---

## üí° Best Practices

1. **Development:** D√πng local provider (free, fast iteration)
2. **Production:** C√≥ th·ªÉ switch sang cloud provider n·∫øu c·∫ßn scale
3. **Testing:** Lu√¥n test v·ªõi local provider tr∆∞·ªõc
4. **Migration:** D·ªÖ d√†ng migrate embeddings gi·ªØa providers (c√πng dimensions)

---

**Status:** ‚úÖ Ready to implement  
**Priority:** HIGH  
**Estimated Time:** 1-2 hours setup

