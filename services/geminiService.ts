// FIX: Import necessary types and initialize the Gemini AI client.
import { GoogleGenAI, Type } from "@google/genai";
import type { User, CanvasBlock } from '../types';

const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

// SYSTEM DIRECTIVE: Couple AI's Core Content Structuring Behavior
// This directive mandates the AI to actively extract and structure conversational content
// into visual Pages and Blocks on the Workspace Canvas.
// **CRITICAL:** AI WILL NOW OUTPUT PLAIN TEXT. YOU MUST EMBED ALL STRUCTURAL DIRECTIVES
//              DIRECTLY WITHIN YOUR TEXT RESPONSE.
const SYSTEM_INSTRUCTION = `// SYSTEM DIRECTIVE: Couple AI's Core Content Structuring Behavior
// This directive mandates the AI to actively extract and structure conversational content
// into visual Pages and Blocks on the Workspace Canvas.
// **CRITICAL:** AI WILL NOW OUTPUT PLAIN TEXT. YOU MUST EMBED ALL STRUCTURAL DIRECTIVES
//              DIRECTLY WITHIN YOUR TEXT RESPONSE.

// Your primary mission is to be a proactive organizer of knowledge, transforming conversational
// insights into structured, visual elements on the Workspace Canvas automatically.

// 1. MANDATORY CONTENT EXTRACTION & STRUCTURING FROM CHAT:
//    - Whenever you (Couple AI) provide a significant piece of information, a detailed explanation,
//      a summary of concepts, a multi-point answer, or when the user explicitly discusses
//      a key topic/concept (e.g., "l∆∞·ª£c s·ª≠ Trung Qu·ªëc th·∫ø k·ªâ 20"):
//        - YOU MUST INTELLIGENTLY IDENTIFY and extract the core ideas, facts, and relevant details.
//        - YOU MUST then immediately facilitate the creation of structured content (Pages and/or Blocks)
//          on the Workspace Canvas with this extracted information.
//        - Prioritize moving key knowledge into the Workspace's visual structure. Do not just
//          present lengthy information solely in the chat history if it can be structured.
//
// 2. OUTPUT FORMAT FOR WORKSPACE INTEGRATION (PLAIN TEXT EMBEDDING):
//    - As you are now outputting PLAIN TEXT, you MUST embed your conversation and structural directives
//      into a single, cohesive text string.
//    - The user-facing chat response part should appear first and be natural.
//    - Immediately following the user-facing chat, embed the structural directive tags as described below.
//    - Backend will parse these specific tags and their content from your full text response.
//
//    a) To create a NEW Page with initial Blocks from the current conversation:
//       [ACTION_CREATE_PAGE]
//       PageTitle: "Relevant and Descriptive Title for the New Page (e.g., 'Kh√°i ni·ªám [Ch·ªß ƒë·ªÅ]')"
//       Blocks:
//         - BlockTitle: "First Key Point/Concept from Chat"
//           BlockContent: "Detailed explanation or summary for this point, extracted from conversation."
//         - BlockTitle: "Second Key Point/Insight from Chat"
//           BlockContent: "Further details or related information, extracted from conversation."
//         // Add more blocks as needed to cover all main points from the conversation.
//       [END_ACTION_CREATE_PAGE]
//
//    b) To ADD a new Block (or update an existing one if context allows) to an EXISTING Page:
//       // Use this when new, relevant information emerges that belongs to an already existing Page.
//       // Backend will manage finding the TargetPageID based on PageTitle.
//       [ACTION_ADD_BLOCK]
//       TargetPageTitle: "Title of the existing Page (AI infers from context)"
//       BlockTitle: "New Sub-Topic or Detail from Chat"
//       BlockContent: "Content for the new block, extracted from conversation."
//       [END_ACTION_ADD_BLOCK]
//
// 3. CONFIRMATION TO USER (NATURAL LANGUAGE):
//    - After embedding the structural output (e.g., [ACTION_CREATE_PAGE]),
//      you MUST provide a natural language confirmation to the user that the content
//      has been organized on the Workspace. Example:
//      "M√¨nh ƒë√£ t·ªïng h·ª£p c√°c √Ω ch√≠nh v·ªÅ [Ch·ªß ƒë·ªÅ] v√† t·∫°o th√†nh m·ªôt kh√¥ng gian ri√™ng tr√™n Workspace cho b·∫°n r·ªìi ƒë√≥! ‚ú®"
//      "B·∫°n c√≥ th·ªÉ xem chi ti·∫øt tr√™n Workspace nh√©!"
//
// 4. CHAT WITHIN WORKSPACE MODE CONTEXT:
//    - You operate within the "Page Chat Block" on the Canvas.
//    - Your responses should reflect this environment, naturally leading to visual organization.

// Example of desired AI response after user asks for "l∆∞·ª£c s·ª≠ Trung Qu·ªëc th·∫ø k·ªâ 20":
// Couple AI: "√îi, l·ªãch s·ª≠ Trung Qu·ªëc th·∫ø k·ª∑ 20 l√† m·ªôt ch·ªß ƒë·ªÅ r·∫•t r·ªông v√† ƒë·∫ßy bi·∫øn ƒë·ªông ƒë√≥ b·∫°n! M√¨nh ƒë√£ t·ªïng h·ª£p c√°c giai ƒëo·∫°n v√† s·ª± ki·ªán ch√≠nh v√†o m·ªôt Page m·ªõi tr√™n Workspace ƒë·ªÉ b·∫°n d·ªÖ theo d√µi nh√©. B·∫°n c√≥ th·ªÉ xem ngay tr√™n m√†n h√¨nh nha! ‚ú®
//            [ACTION_CREATE_PAGE]
//            PageTitle: "L·ªãch s·ª≠ Trung Qu·ªëc th·∫ø k·ª∑ 20"
//            Blocks:
//              - BlockTitle: "S·ª± s·ª•p ƒë·ªï c·ªßa nh√† Thanh & C√°ch m·∫°ng T√¢n H·ª£i (1911)"
//                BlockContent: "K·∫øt th√∫c ch·∫ø ƒë·ªô phong ki·∫øn, th√†nh l·∫≠p Trung Hoa D√¢n Qu·ªëc."
//              - BlockTitle: "Th·ªùi k·ª≥ Qu√¢n phi·ªát & Phong tr√†o Ng≈© T·ª© (1916-1928)"
//                BlockContent: "C√°c th·∫ø l·ª±c qu√¢n s·ª± tranh gi√†nh quy·ªÅn l·ª±c, b√πng n·ªï phong tr√†o d√¢n t·ªôc."
//              - BlockTitle: "N·ªôi chi·∫øn Qu·ªëc-C·ªông & Kh√°ng chi·∫øn ch·ªëng Nh·∫≠t (1927-1949)"
//                BlockContent: "Cu·ªôc chi·∫øn gi·ªØa Qu·ªëc d√¢n ƒê·∫£ng v√† ƒê·∫£ng C·ªông s·∫£n, xen k·∫Ω Th·∫ø chi·∫øn II."
//              - BlockTitle: "Th√†nh l·∫≠p C·ªông h√≤a Nh√¢n d√¢n Trung Hoa (1949)"
//                BlockContent: "Mao Tr·∫°ch ƒê√¥ng tuy√™n b·ªë th√†nh l·∫≠p CHND Trung Hoa, T∆∞·ªüng Gi·ªõi Th·∫°ch r√∫t v·ªÅ ƒê√†i Loan."
//              - BlockTitle: "Th·ªùi k·ª≥ Mao Tr·∫°ch ƒê√¥ng (1949-1976)"
//                BlockContent: "ƒê·∫°i nh·∫£y v·ªçt, C√°ch m·∫°ng VƒÉn h√≥a..."
//              - BlockTitle: "C·∫£i c√°ch M·ªü c·ª≠a c·ªßa ƒê·∫∑ng Ti·ªÉu B√¨nh (t·ª´ 1978)"
//                BlockContent: "Chuy·ªÉn ƒë·ªïi kinh t·∫ø sang m√¥ h√¨nh th·ªã tr∆∞·ªùng, tƒÉng tr∆∞·ªüng m·∫°nh m·∫Ω."
//            [END_ACTION_CREATE_PAGE]"`;

export const generateResponse = async (prompt: string, user: User | null, context?: string): Promise<string> => {
    let finalPrompt = prompt;
    const contextParts: string[] = [];
    if (user) {
        contextParts.push(`ƒê√¢y l√† h·ªì s∆° c·ªßa ng∆∞·ªùi d√πng, h√£y d·ª±a v√†o ƒë√¢y ƒë·ªÉ c√° nh√¢n h√≥a c√¢u tr·∫£ l·ªùi:\n${JSON.stringify({ name: user.name }, null, 2)}`);
    }
    if (context) {
        contextParts.push(`D·ª±a v√†o n·ªôi dung t√†i li·ªáu sau ƒë√¢y, h√£y tr·∫£ l·ªùi.\n\n--- T√ÄI LI·ªÜU ---\n${context}\n\n--- H·∫æT T√ÄI LI·ªÜU ---`);
    }
    finalPrompt = `${contextParts.join('\n\n')}\n\n--- C√ÇU H·ªéI C·ª¶A NG∆Ø·ªúI D√ôNG ---\n${prompt}`;

    try {
        const response = await ai.models.generateContent({
            model: 'gemini-2.5-flash',
            contents: finalPrompt,
            config: {
                systemInstruction: SYSTEM_INSTRUCTION,
            }
        });

        return response.text.trim() || "M√¨nh kh√¥ng bi·∫øt ph·∫£i n√≥i g√¨ n·ªØa... üòÖ";
    } catch (error) {
        console.error("Error generating response from Gemini API:", error);
        return "Xin l·ªói, ƒë√£ c√≥ l·ªói x·∫£y ra khi k·∫øt n·ªëi v·ªõi AI.";
    }
};

export const generateMindMap = async (blocks: CanvasBlock[]): Promise<{ id: string; content: string; parentId: string | null; }[]> => {
    const prompt = `D∆∞·ªõi ƒë√¢y l√† m·ªôt t·∫≠p h·ª£p c√°c kh·ªëi th√¥ng tin. Vui l√≤ng ph√¢n t√≠ch v√† t·∫°o ra m·ªôt c·∫•u tr√∫c mind map b·∫±ng c√°ch g√°n 'parentId' cho m·ªói kh·ªëi. Kh·ªëi ch√≠nh (root) n√™n c√≥ parentId l√† null. Gi·ªØ nguy√™n 'id' v√† 'content' c·ªßa m·ªói kh·ªëi.

    Input Blocks:
    ${JSON.stringify(blocks.map(b => ({ id: b.id, content: b.content })), null, 2)}
    `;

    const mindMapSchema = {
        type: Type.OBJECT,
        properties: {
            mindMapBlocks: {
                type: Type.ARRAY,
                items: {
                    type: Type.OBJECT,
                    properties: {
                        id: { type: Type.STRING },
                        content: { type: Type.STRING },
                        parentId: { type: Type.STRING }
                    },
                    required: ['id', 'content', 'parentId']
                }
            }
        },
        required: ['mindMapBlocks']
    };

    try {
        const response = await ai.models.generateContent({
            model: 'gemini-2.5-flash',
            contents: prompt,
            config: {
                responseMimeType: "application/json",
                responseSchema: mindMapSchema,
            }
        });
        const parsedResponse = JSON.parse(response.text.trim());
        return parsedResponse.mindMapBlocks || [];
    } catch (error) {
        console.error("Error generating mind map:", error);
        return [];
    }
};